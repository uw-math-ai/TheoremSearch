{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531461ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da706fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/51489788.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/51489788.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-19 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/20620662.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/20620662.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-20 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/2924396553.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/2924396553.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-21 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/3406361939.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/3406361939.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-22 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/2271054800.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/2271054800.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-23 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/3096012993.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/3096012993.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "Exception in thread Thread-24 (bg_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13469/4221459241.py\", line 17, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13469/4221459241.py\", line 19, in bg_main\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 354, in update\n",
      "    update_display(obj, display_id=self.display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 306, in update_display\n",
      "    display(obj, display_id=display_id, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 276, in display\n",
      "    publish_display_data(data=obj, metadata=metadata, **kwargs)\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/IPython/core/display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ericleonen/MathCopilot/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x7f354d89ef20>\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"arxiv-full-dataset\"\n",
    "S3_PARSED_PAPERS_DIR = \"parsed_papers\"\n",
    "PARSED_PAPERS_DIR = \"../parsed_papers\"\n",
    "\n",
    "os.makedirs(PARSED_PAPERS_DIR, exist_ok=True)\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=S3_PARSED_PAPERS_DIR)\n",
    "keys = [o[\"Key\"] for o in response.get(\"Contents\", [])]\n",
    "\n",
    "downloaded = 0\n",
    "\n",
    "for key in keys:\n",
    "    if downloaded >= 3:\n",
    "        break\n",
    "\n",
    "    local_path = os.path.join(PARSED_PAPERS_DIR, os.path.basename(key))\n",
    "\n",
    "    if os.path.isdir(local_path):\n",
    "        continue\n",
    "\n",
    "    s3.download_file(BUCKET_NAME, key, local_path)\n",
    "    downloaded += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('math-similarity/Bert-MLM_arXiv-MP-class_zbMath')\n",
    "\n",
    "def load_and_prepare_data(paper_files):\n",
    "    \"\"\"\n",
    "    Loads theorem data from the specified JSON files and prepares it for embedding.\n",
    "    \"\"\"\n",
    "    all_theorems_data = []\n",
    "    for file_path in paper_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                global_notations   = data.get(\"global_notations\", \"\")\n",
    "                global_definitions = data.get(\"global_definitions\", \"\")\n",
    "                global_assumptions = data.get(\"global_assumptions\", \"\")\n",
    "\n",
    "                global_context_parts = []\n",
    "                if global_notations:\n",
    "                    global_context_parts.append(f\"**Global Notations:**\\n{global_notations}\")\n",
    "                if global_definitions:\n",
    "                    global_context_parts.append(f\"**Global Definitions:**\\n{global_definitions}\")\n",
    "                if global_assumptions:\n",
    "                    global_context_parts.append(f\"**Global Assumptions:**\\n{global_assumptions}\")\n",
    "\n",
    "                global_context = \"\\n\\n\".join(global_context_parts)\n",
    "                paper_url     = data.get(\"url\", \"\")\n",
    "                paper_title   = data.get(\"title\", \"N/A\")\n",
    "\n",
    "                for theorem in data.get(\"theorems\", []):\n",
    "                    all_theorems_data.append({\n",
    "                        \"paper_title\":    paper_title,\n",
    "                        \"paper_url\":      paper_url,\n",
    "                        \"type\":           theorem[\"type\"],\n",
    "                        \"content\":        theorem[\"content\"],\n",
    "                        \"global_context\": global_context,\n",
    "                        \"text_to_embed\":  f\"{global_context}\\n\\n**{theorem['type'].capitalize()}:**\\n{theorem['content']}\"\n",
    "                    })\n",
    "        except Exception:\n",
    "            print(\"An error occurred.\")\n",
    "\n",
    "    return all_theorems_data\n",
    "\n",
    "theorems_data = load_and_prepare_data([\n",
    "    os.path.join(PARSED_PAPERS_DIR, f)\n",
    "    for f in os.listdir(PARSED_PAPERS_DIR)\n",
    "    if f.endswith('.json')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079e32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('math-similarity/Bert-MLM_arXiv-MP-class_zbMath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f4152ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext_to_embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtheorems_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:558\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    567\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:488\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    487\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    498\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:363\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().forward(\n\u001b[32m    351\u001b[39m         hidden_states,\n\u001b[32m    352\u001b[39m         attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m         cache_position,\n\u001b[32m    358\u001b[39m     )\n\u001b[32m    360\u001b[39m bsz, tgt_len, _ = hidden_states.size()\n\u001b[32m    362\u001b[39m query_layer = (\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    364\u001b[39m )\n\u001b[32m    366\u001b[39m is_updated = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    367\u001b[39m is_cross_attention = encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MathCopilot/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "embedder.encode([item['text_to_embed'] for item in theorems_data], convert_to_tensor=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
